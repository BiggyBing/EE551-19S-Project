WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}

Starting epoch 1/30
Batch size = 100
Steps in epoch = 500
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}

Starting epoch 1/30
Batch size = 100
Steps in epoch = 500
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}

Starting epoch 1/30
Batch size = 100
Steps in epoch = 500
Epoch: 1/30 Step: 10/500
G_cost             32.7029
D_cost             -57.1530
Wasserstein_D      60.4802
----------------------------------------
Epoch: 1/30 Step: 20/500
G_cost             76.0645
D_cost             -140.2194
Wasserstein_D      142.0209
----------------------------------------
WGAN model: Generator(
  (preprocess_1): Linear(in_features=128, out_features=4096, bias=True)
  (preprocess_2): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (preprocess_3): ReLU()
  (block1): Sequential(
    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (block2): Sequential(
    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (output): Sequential(
    (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2))
    (1): Tanh()
  )
)
Discriminator(
  (main): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.01)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.01)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): LeakyReLU(negative_slope=0.01)
  )
  (linear): Linear(in_features=4096, out_features=1, bias=True)
)

Model Configuration:

{'CRITIC_ITERS': 5,
 'DIM': 64,
 'H': 32,
 'W': 32,
 'generate_num': 10,
 'noise_length': 128}

Training train_options:

{'batch_size': 100,
 'experiment_name': 'WGAN_Cifar10_first_test',
 'number_of_epochs': 30,
 'runs_folder': './runs',
 'start_epoch': 1,
 'train_folder': 'train'}
